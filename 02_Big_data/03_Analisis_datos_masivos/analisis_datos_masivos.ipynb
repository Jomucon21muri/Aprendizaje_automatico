{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fc10f17",
   "metadata": {},
   "source": [
    "# üìà An√°lisis de Datos Masivos\n",
    "## T√©cnicas y Algoritmos Escalables\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Jomucon21muri/Aprendizaje_automatico/blob/main/02_Big_data/03_Analisis_datos_masivos/analisis_datos_masivos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Resumen\n",
    "\n",
    "An√°lisis estad√≠stico y ML aplicados a datasets masivos distribuidos.\n",
    "\n",
    "### üéØ Objetivos\n",
    "- Estad√≠stica descriptiva a escala\n",
    "- ML distribuido (MLlib de Spark)\n",
    "- Procesamiento de streams en tiempo real\n",
    "- Visualizaci√≥n de Big Data\n",
    "\n",
    "### üî¨ T√©cnicas Escalables\n",
    "\n",
    "**Algoritmos Distribuidos**:\n",
    "- **K-Means**: Clustering paralelo\n",
    "- **Alternating Least Squares (ALS)**: Sistemas de recomendaci√≥n\n",
    "- **Gradient Boosting**: √Årboles distribuidos\n",
    "- **Random Forest**: Ensambles paralelos\n",
    "\n",
    "**Streaming Analytics**:\n",
    "- **Window Operations**: An√°lisis en ventanas temporales\n",
    "- **Stateful Processing**: Mantener estado entre batches\n",
    "- **Watermarks**: Manejo de datos tard√≠os\n",
    "\n",
    "### üìä Apache Spark MLlib\n",
    "\n",
    "```python\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.recommendation import ALS\n",
    "```\n",
    "\n",
    "### üéØ Casos de Uso\n",
    "- An√°lisis de comportamiento de usuarios\n",
    "- Detecci√≥n de fraude en tiempo real\n",
    "- Sistemas de recomendaci√≥n\n",
    "- An√°lisis de logs y m√©tricas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9700407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - An√°lisis a escala con Pandas (simulaci√≥n)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simular an√°lisis de logs masivos\n",
    "np.random.seed(42)\n",
    "n_records = 100000\n",
    "\n",
    "data = {\n",
    "    'timestamp': pd.date_range('2024-01-01', periods=n_records, freq='1min'),\n",
    "    'user_id': np.random.randint(1, 10000, n_records),\n",
    "    'page_views': np.random.randint(1, 20, n_records),\n",
    "    'duration_sec': np.random.exponential(120, n_records),\n",
    "    'device': np.random.choice(['mobile', 'desktop', 'tablet'], n_records)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# An√°lisis agregado\n",
    "print(\"üìä An√°lisis de Logs Web (100k registros)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nüìà Estad√≠sticas Globales:\")\n",
    "print(f\"  ‚Ä¢ Total pageviews: {df['page_views'].sum():,}\")\n",
    "print(f\"  ‚Ä¢ Usuarios √∫nicos: {df['user_id'].nunique():,}\")\n",
    "print(f\"  ‚Ä¢ Duraci√≥n promedio: {df['duration_sec'].mean():.1f}s\")\n",
    "print(f\"\\nüì± Por Dispositivo:\")\n",
    "print(df.groupby('device')['page_views'].agg(['count', 'sum', 'mean']))\n",
    "print(\"\\n‚úÖ T√©cnicas Big Data:\")\n",
    "print(\"  ‚Ä¢ Partitioning: Dividir datos por fecha/clave\")\n",
    "print(\"  ‚Ä¢ Sampling: Analizar subconjuntos representativos\")\n",
    "print(\"  ‚Ä¢ Approximate Algorithms: HyperLogLog, Count-Min Sketch\")\n",
    "print(\"  ‚Ä¢ Columnar Storage: Parquet, ORC para queries eficientes\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
