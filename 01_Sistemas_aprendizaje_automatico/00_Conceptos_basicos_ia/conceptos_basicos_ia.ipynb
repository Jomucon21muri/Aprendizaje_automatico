{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3418a1",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Jomucon21muri/Aprendizaje_automatico/blob/main/01_Sistemas_aprendizaje_automatico/00_Conceptos_basicos_ia/conceptos_basicos_ia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# Conceptos b√°sicos de IA\n",
    "\n",
    "## Introducci√≥n\n",
    "\n",
    "Bienvenido al notebook de **conceptos b√°sicos de inteligencia artificial**. En este cuaderno exploraremos los fundamentos de la IA, desde su definici√≥n hasta sus aplicaciones pr√°cticas.\n",
    "\n",
    "### Temas que veremos:\n",
    "\n",
    "1. **Definici√≥n de inteligencia artificial**\n",
    "   - ¬øQu√© es la IA?\n",
    "   - Historia y evoluci√≥n\n",
    "   - Diferencia entre IA d√©bil y fuerte\n",
    "\n",
    "2. **Campos de aplicaci√≥n**\n",
    "   - Visi√≥n computacional\n",
    "   - Procesamiento de lenguaje natural\n",
    "   - Sistemas de recomendaci√≥n\n",
    "   - Rob√≥tica y automatizaci√≥n\n",
    "\n",
    "3. **Representaci√≥n del conocimiento**\n",
    "   - B√∫squeda y optimizaci√≥n\n",
    "   - L√≥gica y razonamiento\n",
    "   - Algoritmos fundamentales\n",
    "\n",
    "4. **Ejercicios pr√°cticos**\n",
    "   - Implementaci√≥n de algoritmos b√°sicos\n",
    "   - An√°lisis de casos de uso\n",
    "   - Reflexi√≥n sobre √©tica en IA\n",
    "\n",
    "---\n",
    "\n",
    "**Requisitos previos:**\n",
    "- Conocimientos b√°sicos de programaci√≥n en Python\n",
    "- Comprensi√≥n de estructuras de datos b√°sicas\n",
    "\n",
    "**Duraci√≥n estimada:** 4-6 horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1152e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"¬°Entorno configurado correctamente!\")\n",
    "print(\"Est√°s listo para comenzar con los conceptos b√°sicos de IA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a6f6a",
   "metadata": {},
   "source": [
    "# üìö Fundamentos de la Inteligencia Artificial\n",
    "\n",
    "---\n",
    "\n",
    "## Resumen\n",
    "\n",
    "El presente documento constituye una introducci√≥n sistem√°tica a los conceptos fundamentales de la **Inteligencia Artificial (IA)**, disciplina que ha experimentado un desarrollo exponencial en las √∫ltimas d√©cadas. \n",
    "\n",
    "En este notebook exploraremos:\n",
    "- Definiciones formales y perspectivas de la IA\n",
    "- Historia y evoluci√≥n del campo\n",
    "- Tipos de IA: d√©bil vs fuerte\n",
    "- Paradigmas de aprendizaje\n",
    "- Aplicaciones contempor√°neas\n",
    "- **Ejemplos pr√°cticos ejecutables**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345f7865",
   "metadata": {},
   "source": [
    "## 1. Definici√≥n Formal de Inteligencia Artificial\n",
    "\n",
    "La **Inteligencia Artificial** se define como una rama interdisciplinaria de las ciencias de la computaci√≥n dedicada al dise√±o, desarrollo e implementaci√≥n de sistemas computacionales capaces de ejecutar tareas que tradicionalmente requieren inteligencia humana.\n",
    "\n",
    "### Perspectivas de la IA:\n",
    "\n",
    "1. **Perspectiva Computacional**: Sistemas que procesan informaci√≥n mediante algoritmos complejos para emular capacidades cognitivas humanas.\n",
    "\n",
    "2. **Perspectiva Funcional**: Entidades artificiales que manifiestan comportamientos inteligentes observables.\n",
    "\n",
    "3. **Perspectiva Filos√≥fica**: Sistemas que exhiben propiedades emergentes de inteligencia, planteando interrogantes sobre la naturaleza de la cognici√≥n.\n",
    "\n",
    "### Caracter√≠sticas Fundamentales:\n",
    "\n",
    "- **Capacidad de Aprendizaje Adaptativo**: Modificar comportamiento bas√°ndose en experiencias previas\n",
    "- **Razonamiento Autom√°tico**: Realizar inferencias l√≥gicas y derivar conclusiones\n",
    "- **Resoluci√≥n de Problemas Complejos**: Abordar problemas mal definidos con espacios de b√∫squeda extensos\n",
    "- **Procesamiento del Lenguaje Natural (PLN)**: Comprender e interpretar lenguaje humano\n",
    "- **Visi√≥n Computacional**: Procesar y analizar informaci√≥n visual\n",
    "- **Planificaci√≥n y Toma de Decisiones**: Establecer secuencias de acciones orientadas a objetivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05027efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo pr√°ctico: Simulaci√≥n simple de un agente inteligente\n",
    "# Implementaremos un agente que aprende a navegar en un entorno simple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "class SimpleAgent:\n",
    "    \"\"\"\n",
    "    Agente simple que aprende a moverse en una cuadr√≠cula\n",
    "    Caracter√≠sticas de IA:\n",
    "    - Aprendizaje adaptativo (Q-learning b√°sico)\n",
    "    - Toma de decisiones\n",
    "    - Exploraci√≥n del entorno\n",
    "    \"\"\"\n",
    "    def __init__(self, grid_size=5):\n",
    "        self.grid_size = grid_size\n",
    "        self.position = [0, 0]\n",
    "        self.goal = [grid_size-1, grid_size-1]\n",
    "        self.q_table = defaultdict(lambda: np.zeros(4))  # 4 acciones: arriba, abajo, izq, der\n",
    "        self.actions = {0: [-1, 0], 1: [1, 0], 2: [0, -1], 3: [0, 1]}\n",
    "        self.learning_rate = 0.1\n",
    "        self.discount_factor = 0.95\n",
    "        self.epsilon = 0.1  # Exploraci√≥n\n",
    "        \n",
    "    def get_state(self):\n",
    "        return tuple(self.position)\n",
    "    \n",
    "    def choose_action(self):\n",
    "        \"\"\"Estrategia epsilon-greedy\"\"\"\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return np.random.choice(4)  # Exploraci√≥n\n",
    "        else:\n",
    "            return np.argmax(self.q_table[self.get_state()])  # Explotaci√≥n\n",
    "    \n",
    "    def move(self, action):\n",
    "        \"\"\"Ejecutar acci√≥n y retornar recompensa\"\"\"\n",
    "        new_pos = [self.position[0] + self.actions[action][0],\n",
    "                   self.position[1] + self.actions[action][1]]\n",
    "        \n",
    "        # Verificar l√≠mites\n",
    "        if 0 <= new_pos[0] < self.grid_size and 0 <= new_pos[1] < self.grid_size:\n",
    "            self.position = new_pos\n",
    "        \n",
    "        # Recompensa\n",
    "        if self.position == self.goal:\n",
    "            return 100  # ¬°Meta alcanzada!\n",
    "        else:\n",
    "            return -1  # Penalizaci√≥n por movimiento\n",
    "    \n",
    "    def learn(self, old_state, action, reward, new_state):\n",
    "        \"\"\"Actualizaci√≥n Q-learning\"\"\"\n",
    "        old_q = self.q_table[old_state][action]\n",
    "        max_future_q = np.max(self.q_table[new_state])\n",
    "        new_q = old_q + self.learning_rate * (reward + self.discount_factor * max_future_q - old_q)\n",
    "        self.q_table[old_state][action] = new_q\n",
    "    \n",
    "    def reset(self):\n",
    "        self.position = [0, 0]\n",
    "\n",
    "# Entrenar el agente\n",
    "agent = SimpleAgent(grid_size=5)\n",
    "rewards_history = []\n",
    "\n",
    "print(\"ü§ñ Entrenando agente inteligente...\")\n",
    "for episode in range(500):\n",
    "    agent.reset()\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    \n",
    "    while steps < 100:  # M√°ximo 100 pasos por episodio\n",
    "        old_state = agent.get_state()\n",
    "        action = agent.choose_action()\n",
    "        reward = agent.move(action)\n",
    "        new_state = agent.get_state()\n",
    "        \n",
    "        agent.learn(old_state, action, reward, new_state)\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "        \n",
    "        if agent.position == agent.goal:\n",
    "            break\n",
    "    \n",
    "    rewards_history.append(total_reward)\n",
    "\n",
    "# Visualizar aprendizaje\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(rewards_history, alpha=0.6)\n",
    "plt.plot(np.convolve(rewards_history, np.ones(50)/50, mode='valid'), 'r', linewidth=2, label='Media m√≥vil (50 episodios)')\n",
    "plt.xlabel('Episodio')\n",
    "plt.ylabel('Recompensa total')\n",
    "plt.title('Aprendizaje del Agente')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Visualizar pol√≠tica aprendida\n",
    "policy_grid = np.zeros((agent.grid_size, agent.grid_size))\n",
    "arrows = {0: '‚Üë', 1: '‚Üì', 2: '‚Üê', 3: '‚Üí'}\n",
    "for i in range(agent.grid_size):\n",
    "    for j in range(agent.grid_size):\n",
    "        state = (i, j)\n",
    "        if state in agent.q_table:\n",
    "            policy_grid[i, j] = np.argmax(agent.q_table[state])\n",
    "\n",
    "plt.imshow(policy_grid, cmap='viridis')\n",
    "plt.title('Pol√≠tica Aprendida (mejores acciones)')\n",
    "plt.colorbar(label='Acci√≥n √≥ptima')\n",
    "for i in range(agent.grid_size):\n",
    "    for j in range(agent.grid_size):\n",
    "        plt.text(j, i, arrows[int(policy_grid[i, j])], \n",
    "                ha=\"center\", va=\"center\", color=\"white\", fontsize=20)\n",
    "plt.xlabel('Posici√≥n X')\n",
    "plt.ylabel('Posici√≥n Y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Agente entrenado exitosamente!\")\n",
    "print(f\"Recompensa promedio √∫ltimos 100 episodios: {np.mean(rewards_history[-100:]):.2f}\")\n",
    "print(\"\\nEste ejemplo demuestra:\")\n",
    "print(\"- Aprendizaje adaptativo (mejora con experiencia)\")\n",
    "print(\"- Toma de decisiones (elige acciones √≥ptimas)\")\n",
    "print(\"- Exploraci√≥n del entorno (balancea exploraci√≥n y explotaci√≥n)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb02f0c1",
   "metadata": {},
   "source": [
    "## 2. Evoluci√≥n Hist√≥rica de la IA\n",
    "\n",
    "### 2.1 G√©nesis y Consolidaci√≥n (1950-1974)\n",
    "\n",
    "El origen formal de la IA se sit√∫a en la **Conferencia de Dartmouth de 1956**, organizada por John McCarthy, Marvin Minsky, Claude Shannon y Nathaniel Rochester.\n",
    "\n",
    "**Hitos importantes:**\n",
    "\n",
    "- **1956**: Conferencia de Dartmouth - Nacimiento oficial de la IA\n",
    "- **1956**: Logic Theorist (Newell y Simon) - Primer programa de IA que demostr√≥ teoremas\n",
    "- **1959**: Arthur Samuel desarrolla un programa que juega damas\n",
    "- **1966**: ELIZA - Primer chatbot (Joseph Weizenbaum)\n",
    "\n",
    "**Primer Invierno de la IA (1974-1980)**: Reducci√≥n de financiamiento debido a limitaciones t√©cnicas y expectativas no cumplidas.\n",
    "\n",
    "### 2.2 Renacimiento con Sistemas Expertos (1980-1987)\n",
    "\n",
    "Los **sistemas expertos** encapsulaban conocimiento especializado en dominios espec√≠ficos:\n",
    "\n",
    "- **MYCIN**: Diagn√≥stico m√©dico\n",
    "- **DENDRAL**: An√°lisis qu√≠mico\n",
    "- **XCON**: Configuraci√≥n de sistemas computacionales\n",
    "\n",
    "### 2.3 Segundo Invierno y Resurgimiento (1987-2011)\n",
    "\n",
    "- **1997**: Deep Blue de IBM derrota a Garry Kasparov en ajedrez\n",
    "- **2011**: Watson de IBM gana en Jeopardy!\n",
    "\n",
    "### 2.4 Era del Aprendizaje Profundo (2012-presente)\n",
    "\n",
    "- **2012**: AlexNet revoluciona visi√≥n computacional\n",
    "- **2016**: AlphaGo derrota a Lee Sedol en Go\n",
    "- **2017**: Transformers revolucionan NLP\n",
    "- **2022**: ChatGPT alcanza 100M de usuarios en 2 meses\n",
    "- **2023-2024**: Explosi√≥n de LLMs (GPT-4, Claude, Gemini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1168df81",
   "metadata": {},
   "source": [
    "## 3. IA D√©bil vs IA Fuerte\n",
    "\n",
    "### IA D√©bil (Narrow AI o ANI)\n",
    "\n",
    "Sistemas dise√±ados para tareas espec√≠ficas:\n",
    "- Reconocimiento facial\n",
    "- Asistentes virtuales (Siri, Alexa)\n",
    "- Sistemas de recomendaci√≥n (Netflix, Spotify)\n",
    "- Veh√≠culos aut√≥nomos\n",
    "- Diagn√≥stico m√©dico asistido\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- Dominio espec√≠fico\n",
    "- No posee consciencia\n",
    "- **Actual estado del arte** (todos los sistemas actuales)\n",
    "\n",
    "### IA Fuerte (AGI - Artificial General Intelligence)\n",
    "\n",
    "Sistema hipot√©tico con capacidades cognitivas equivalentes a humanos:\n",
    "- Razonamiento abstracto\n",
    "- Transferencia de conocimiento entre dominios\n",
    "- Consciencia y autoconciencia\n",
    "- Creatividad genuina\n",
    "\n",
    "**Estado:** A√∫n no alcanzada, tema de investigaci√≥n activa\n",
    "\n",
    "### Super IA (ASI)\n",
    "\n",
    "Inteligencia que supera capacidades humanas en todos los dominios:\n",
    "- Especulaci√≥n te√≥rica\n",
    "- Preocupaciones √©ticas y existenciales\n",
    "- Tema de debate en filosof√≠a y seguridad de IA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4047e180",
   "metadata": {},
   "source": [
    "## 4. Paradigmas de Aprendizaje Autom√°tico\n",
    "\n",
    "### 4.1 Aprendizaje Supervisado\n",
    "\n",
    "**Definici√≥n:** El modelo aprende de datos etiquetados (pares entrada-salida conocidos)\n",
    "\n",
    "**Ejemplos:**\n",
    "- Clasificaci√≥n: Spam vs No Spam\n",
    "- Regresi√≥n: Predicci√≥n de precios\n",
    "- Reconocimiento de im√°genes\n",
    "\n",
    "**Algoritmos:** Regresi√≥n Lineal, SVM, Random Forest, Redes Neuronales\n",
    "\n",
    "### 4.2 Aprendizaje No Supervisado\n",
    "\n",
    "**Definici√≥n:** El modelo encuentra patrones en datos sin etiquetas\n",
    "\n",
    "**Ejemplos:**\n",
    "- Clustering de clientes\n",
    "- Reducci√≥n de dimensionalidad\n",
    "- Detecci√≥n de anomal√≠as\n",
    "\n",
    "**Algoritmos:** K-Means, PCA, DBSCAN, Autoencoders\n",
    "\n",
    "### 4.3 Aprendizaje por Refuerzo\n",
    "\n",
    "**Definici√≥n:** Agente aprende mediante interacci√≥n con entorno, maximizando recompensas\n",
    "\n",
    "**Ejemplos:**\n",
    "- Juegos (AlphaGo, AlphaZero)\n",
    "- Rob√≥tica\n",
    "- Veh√≠culos aut√≥nomos\n",
    "\n",
    "**Algoritmos:** Q-Learning, PPO, DQN, A3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd9e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo Pr√°ctico: Comparaci√≥n de los 3 Paradigmas de Aprendizaje\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. APRENDIZAJE SUPERVISADO\n",
    "print(\"üéØ 1. Aprendizaje Supervisado (Clasificaci√≥n)\")\n",
    "X_super, y_super = make_classification(n_samples=200, n_features=2, n_redundant=0,\n",
    "                                       n_informative=2, n_clusters_per_class=1,\n",
    "                                       random_state=42)\n",
    "\n",
    "model_super = LogisticRegression()\n",
    "model_super.fit(X_super, y_super)\n",
    "\n",
    "# Visualizar\n",
    "axes[0].scatter(X_super[y_super==0, 0], X_super[y_super==0, 1], \n",
    "               c='blue', label='Clase 0 (Etiquetada)', alpha=0.6, s=50)\n",
    "axes[0].scatter(X_super[y_super==1, 0], X_super[y_super==1, 1], \n",
    "               c='red', label='Clase 1 (Etiquetada)', alpha=0.6, s=50)\n",
    "\n",
    "# Frontera de decisi√≥n\n",
    "x_min, x_max = X_super[:, 0].min() - 1, X_super[:, 0].max() + 1\n",
    "y_min, y_max = X_super[:, 1].min() - 1, X_super[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "Z = model_super.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "axes[0].contourf(xx, yy, Z, alpha=0.2, levels=1, colors=['blue', 'red'])\n",
    "axes[0].set_title('Aprendizaje Supervisado\\n(Datos Etiquetados)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "print(f\"   Accuracy: {model_super.score(X_super, y_super):.2%}\")\n",
    "\n",
    "# 2. APRENDIZAJE NO SUPERVISADO\n",
    "print(\"\\nüîç 2. Aprendizaje No Supervisado (Clustering)\")\n",
    "X_unsuper, _ = make_blobs(n_samples=200, centers=3, n_features=2,\n",
    "                          random_state=42, cluster_std=0.8)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_unsuper)\n",
    "\n",
    "axes[1].scatter(X_unsuper[:, 0], X_unsuper[:, 1], c=clusters, \n",
    "               cmap='viridis', s=50, alpha=0.6, edgecolors='k')\n",
    "axes[1].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
    "               c='red', marker='X', s=300, edgecolors='black', linewidths=2,\n",
    "               label='Centroides')\n",
    "axes[1].set_title('Aprendizaje No Supervisado\\n(Datos SIN Etiquetas)', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "print(f\"   Clusters encontrados: {len(np.unique(clusters))}\")\n",
    "print(f\"   Inertia: {kmeans.inertia_:.2f}\")\n",
    "\n",
    "# 3. APRENDIZAJE POR REFUERZO (Simulaci√≥n simple)\n",
    "print(\"\\nü§ñ 3. Aprendizaje por Refuerzo (Navegaci√≥n)\")\n",
    "\n",
    "# Grid world simple\n",
    "grid_size = 5\n",
    "start = (0, 0)\n",
    "goal = (4, 4)\n",
    "obstacles = [(1, 1), (2, 2), (3, 1)]\n",
    "\n",
    "# Crear visualizaci√≥n del grid\n",
    "grid = np.zeros((grid_size, grid_size))\n",
    "for obs in obstacles:\n",
    "    grid[obs] = -1  # Obst√°culos\n",
    "grid[goal] = 10  # Meta\n",
    "\n",
    "# Simular trayectoria aprendida\n",
    "path = [(0,0), (0,1), (0,2), (0,3), (0,4), (1,4), (2,4), (3,4), (4,4)]\n",
    "\n",
    "axes[2].imshow(grid, cmap='RdYlGn', alpha=0.3, vmin=-1, vmax=10)\n",
    "axes[2].grid(True, which='both', color='black', linewidth=1.5)\n",
    "axes[2].set_xticks(np.arange(-0.5, grid_size, 1), minor=True)\n",
    "axes[2].set_yticks(np.arange(-0.5, grid_size, 1), minor=True)\n",
    "axes[2].grid(which='minor', color='black', linewidth=1)\n",
    "\n",
    "# Dibujar camino\n",
    "path_x = [p[1] for p in path]\n",
    "path_y = [p[0] for p in path]\n",
    "axes[2].plot(path_x, path_y, 'b-', linewidth=3, alpha=0.7, label='Trayectoria Aprendida')\n",
    "axes[2].plot(path_x[0], path_y[0], 'go', markersize=15, label='Inicio')\n",
    "axes[2].plot(path_x[-1], path_y[-1], 'r*', markersize=20, label='Meta')\n",
    "\n",
    "# Marcar obst√°culos\n",
    "for obs in obstacles:\n",
    "    axes[2].add_patch(Rectangle((obs[1]-0.4, obs[0]-0.4), 0.8, 0.8, \n",
    "                                fill=True, color='black', alpha=0.5))\n",
    "\n",
    "axes[2].set_title('Aprendizaje por Refuerzo\\n(Interacci√≥n con Entorno)', fontsize=14, fontweight='bold')\n",
    "axes[2].legend(loc='upper left')\n",
    "axes[2].set_xlim(-0.5, grid_size-0.5)\n",
    "axes[2].set_ylim(grid_size-0.5, -0.5)\n",
    "\n",
    "print(f\"   Pasos hasta meta: {len(path)}\")\n",
    "print(f\"   Obst√°culos evitados: {len(obstacles)}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMEN DE PARADIGMAS:\")\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ Supervisado: Aprendemos de EJEMPLOS ETIQUETADOS\")\n",
    "print(\"‚úÖ No Supervisado: Descubrimos PATRONES OCULTOS\")  \n",
    "print(\"‚úÖ Refuerzo: Aprendemos mediante PRUEBA Y ERROR con recompensas\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3ad69",
   "metadata": {},
   "source": [
    "## 5. Aplicaciones Contempor√°neas de la IA\n",
    "\n",
    "### 5.1 Procesamiento de Lenguaje Natural (NLP)\n",
    "\n",
    "- **Chatbots y Asistentes Virtuales**: ChatGPT, Claude, Gemini\n",
    "- **Traducci√≥n Autom√°tica**: Google Translate, DeepL\n",
    "- **An√°lisis de Sentimientos**: Monitoreo de redes sociales\n",
    "- **Generaci√≥n de Texto**: GPT-4, Claude 3.5\n",
    "\n",
    "### 5.2 Visi√≥n Computacional\n",
    "\n",
    "- **Reconocimiento Facial**: Seguridad, autenticaci√≥n\n",
    "- **Veh√≠culos Aut√≥nomos**: Tesla, Waymo\n",
    "- **Diagn√≥stico M√©dico**: Detecci√≥n de tumores, an√°lisis de radiograf√≠as\n",
    "- **Realidad Aumentada**: Filtros de Instagram, Snapchat\n",
    "\n",
    "### 5.3 Sistemas de Recomendaci√≥n\n",
    "\n",
    "- **Streaming**: Netflix, Spotify, YouTube\n",
    "- **E-commerce**: Amazon, Alibaba\n",
    "- **Redes Sociales**: TikTok, Instagram\n",
    "\n",
    "### 5.4 Rob√≥tica y Automatizaci√≥n\n",
    "\n",
    "- **Manufactura**: Robots industriales\n",
    "- **Log√≠stica**: Almacenes automatizados (Amazon)\n",
    "- **Servicios**: Robots de limpieza, atenci√≥n al cliente\n",
    "\n",
    "### 5.5 Ciencia y Investigaci√≥n\n",
    "\n",
    "- **Descubrimiento de F√°rmacos**: AlphaFold para estructura de prote√≠nas\n",
    "- **Astronom√≠a**: Clasificaci√≥n de galaxias\n",
    "- **Clima**: Predicci√≥n meteorol√≥gica avanzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f91da2",
   "metadata": {},
   "source": [
    "## 6. Consideraciones √âticas y Sociales\n",
    "\n",
    "### 6.1 Desaf√≠os √âticos\n",
    "\n",
    "**Sesgo Algor√≠tmico**: Los modelos pueden perpetuar o amplificar sesgos presentes en datos de entrenamiento\n",
    "- Ejemplo: Sistemas de reconocimiento facial con menor precisi√≥n en minor√≠as\n",
    "- Soluci√≥n: Datasets diversos, auditor√≠as de fairness\n",
    "\n",
    "**Privacidad y Protecci√≥n de Datos**: \n",
    "- GDPR en Europa\n",
    "- Derecho al olvido\n",
    "- Consentimiento informado\n",
    "\n",
    "**Transparencia y Explicabilidad (XAI)**:\n",
    "- \"Cajas negras\" en deep learning\n",
    "- Necesidad de explicaciones en decisiones cr√≠ticas (medicina, justicia)\n",
    "- T√©cnicas: SHAP, LIME, Attention mechanisms\n",
    "\n",
    "### 6.2 Impacto Laboral\n",
    "\n",
    "**Automatizaci√≥n**:\n",
    "- Desplazamiento de empleos rutinarios\n",
    "- Creaci√≥n de nuevos roles (ML Engineer, Data Scientist)\n",
    "- Necesidad de re-capacitaci√≥n\n",
    "\n",
    "**Colaboraci√≥n Humano-IA**:\n",
    "- IA como herramienta de aumento (augmentation)\n",
    "- Mejora de productividad\n",
    "- Nuevas formas de trabajo\n",
    "\n",
    "### 6.3 Seguridad de IA\n",
    "\n",
    "**Riesgos**:\n",
    "- Ataques adversariales\n",
    "- Deepfakes y desinformaci√≥n\n",
    "- Uso malicioso de IA\n",
    "\n",
    "**Mitigaci√≥n**:\n",
    "- Desarrollo responsable\n",
    "- Regulaci√≥n y marcos legales\n",
    "- Investigaci√≥n en AI Safety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c507e1d9",
   "metadata": {},
   "source": [
    "## 7. Ejercicios Pr√°cticos y Conclusiones\n",
    "\n",
    "### Ejercicios Propuestos:\n",
    "\n",
    "1. **Implementa un clasificador simple** usando scikit-learn para un dataset de tu elecci√≥n\n",
    "2. **Explora clustering** con K-Means en un dataset de im√°genes (MNIST)\n",
    "3. **Investiga un caso de uso de IA** en tu industria de inter√©s\n",
    "4. **Analiza sesgos** en un dataset p√∫blico (ej: compas-scores-two-years)\n",
    "\n",
    "### Recursos Adicionales:\n",
    "\n",
    "- **Libros**:\n",
    "  - \"Artificial Intelligence: A Modern Approach\" - Russell & Norvig\n",
    "  - \"Deep Learning\" - Goodfellow, Bengio & Courville\n",
    "  \n",
    "- **Cursos Online**:\n",
    "  - Andrew Ng - Machine Learning (Coursera)\n",
    "  - fast.ai - Practical Deep Learning\n",
    "  \n",
    "- **Comunidades**:\n",
    "  - Kaggle - Competencias y datasets\n",
    "  - Papers with Code - √öltimas investigaciones\n",
    "  - Hugging Face - Modelos pre-entrenados\n",
    "\n",
    "### Conclusiones:\n",
    "\n",
    "‚úÖ La IA es un campo interdisciplinario en r√°pida evoluci√≥n\n",
    "\n",
    "‚úÖ Existen m√∫ltiples paradigmas de aprendizaje (supervisado, no supervisado, refuerzo)\n",
    "\n",
    "‚úÖ Las aplicaciones son vastas: NLP, visi√≥n computacional, rob√≥tica, etc.\n",
    "\n",
    "‚úÖ Consideraciones √©ticas son fundamentales para desarrollo responsable\n",
    "\n",
    "‚úÖ El futuro de la IA incluye AGI, pero estamos en la era de IA d√©bil/especializada\n",
    "\n",
    "---\n",
    "\n",
    "**¬°Siguiente paso**: Profundizar en Machine Learning Supervisado!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
